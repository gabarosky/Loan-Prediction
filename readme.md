# Loan Pre-Approval Predictor  
**Machine Learning Â· Python Â· Streamlit**

This project is a small end-to-end Machine Learning application that predicts the **pre-approval status of a loan application** based on applicant information.  
It includes data preprocessing, feature engineering, model training, and an interactive web interface built with **Streamlit**.

> âš ï¸ **Disclaimer**  
> The predictions generated by this application are **non-binding and for informational purposes only**.  
> They do **not** constitute a financial offer or an official credit decision.

---

## ğŸš€ Features

- End-to-end ML pipeline using **scikit-learn Pipelines**
- Custom feature engineering transformer
- Categorical and numerical preprocessing
- Dimensionality reduction with PCA
- Classification model (CatBoost)
- Interactive Streamlit web application
- Reproducible and modular project structure

---

## ğŸŒ Live Demo

The application is deployed on **Streamlit Cloud** and can be accessed here:

ğŸ”— **https://loan-prediction-gabarosky.streamlit.app/**

---

## ğŸ“ Project Structure

```

.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__
â”‚   â”œâ”€â”€ form.py              # UI form and results display
â”‚   â””â”€â”€ prediction.py        # Model loading and inference
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ custom_transformers.py  # Custom FeatureEngineer transformer
â”‚   â””â”€â”€ train_model.py          # Training pipeline script
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv            # Original dataset (input)
â”‚   â””â”€â”€ cleaned.csv          # Cleaned dataset (generated)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ trained_model.pkl    # Trained ML pipeline (generated)
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ data_exploration.ipynb  # EDA, treatment of missings, outliers and strange values.
â”‚   â”œâ”€â”€ feature.ipynb           # Feature engineering
â”‚   â””â”€â”€ machine_learning.ipynb  # Test, validation and selection of model
â”‚
â”‚   main.py                  # Streamlit entry point
â”œâ”€â”€ config.py                # Centralized project paths
â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   HOW_TO_REPRODUCE.md
â”‚   MODEL_CARD.md
â””â”€â”€ README.md


````

---

## ğŸ“Š Dataset Source

The dataset used in this project comes from the following public machine learning competition:

**Loan Prediction Practice Problem (III)**  
Organized by **Analytics Vidhya**

ğŸ”— https://www.analyticsvidhya.com/datahack/contest/practice-problem-loan-prediction-iii/

The data is used **strictly for educational and demonstration purposes**.  
All rights and credits belong to Analytics Vidhya and the original data providers.

---

## ğŸ““ Notebooks

The `notebook/` directory contains **experimental and exploratory Jupyter notebooks**, used for:

- Exploratory Data Analysis (EDA)
- Feature engineering experimentation
- Model comparison and hyperparameter tuning
- Validation of preprocessing and modeling decisions

âš ï¸ These notebooks are **not part of the production pipeline** and should be considered exploratory only.  
The **authoritative training and inference logic** is implemented in the `scripts/` and `app/` directories.

---

## ğŸ§  Machine Learning Pipeline

The model training pipeline consists of the following steps:

1. **Feature Engineering**
   - Total Income
   - Estimated Loan Installment
   - Income Impact Ratio

2. **Preprocessing**
   - Numerical features: `StandardScaler` + `PCA`
   - Categorical features: `SimpleImputer` + `OneHotEncoder`

3. **Model**
   - `CatBoostClassifier`

All steps are wrapped in a single `scikit-learn Pipeline` to ensure consistency between training and inference.

---

## ğŸ› ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/gabarosky/Loan-Prediction.git
cd Loan-Prediction
````

### 2. Create a virtual environment (recommended)

```bash
python -m venv .venv
```

Activate it:

* **Windows**

```bash
.venv\Scripts\activate
```

* **Linux / macOS**

```bash
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ‹ï¸ Train the Model

Ensure `train.csv` is present in the `data/` directory.

```bash
python scripts/train_model.py
```

This process will:

* Clean the raw dataset
* Train the complete ML pipeline
* Save the trained model to `models/trained_model.pkl`

---

## ğŸ–¥ï¸ Run the Streamlit App

```bash
streamlit run main.py
```

Open your browser at:

```
http://localhost:8501
```
---

## â˜ï¸ Deployment (Streamlit Cloud)

âš ï¸ **Important â€“ Python version selection**

When deploying this application on **Streamlit Cloud**, you must **manually select Python 3.11**
from the Python version dropdown in the deployment interface.

Although a `runtime.txt` file is included in the repository, Streamlit Cloud currently prioritizes
the Python version selected in the UI over repository configuration.
Failing to select Python 3.11 may result in dependency installation errors (e.g. with `catboost`).

**Steps:**
1. Create a new app in Streamlit Cloud
2. Select **Python 3.11** from the version dropdown
3. Deploy the application

This is a known platform limitation and not a project-specific issue.

---


## ğŸ” Reproducibility Notes

* All preprocessing and feature engineering steps are included in the pipeline
* The same pipeline object is used for training and prediction
* Project paths are centralized in `config.py`
* Model artifacts are explicitly versioned in `models/`

